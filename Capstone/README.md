# Audio Palette

In this project we tackle an interesting problem of generating music from image input. Leveraging deep learning techniques, our study presents a robust method for generating soundtracks from visual content. We discuss the methods used along with the underlying architectures and demonstrate its effectiveness in creating a suitable auditory experience.


The research highlights potential application in multimedia, immersive storytelling etc. This approach opens new horizons at the intersection of visual and auditory perception, showcasing a promising avenue for cross-modal translation in the ever-evolving field of technology and arts.

## Demo

The live link can be found [here](https://huggingface.co/spaces/onlycaps/audio_palette) on HuggingFace.
